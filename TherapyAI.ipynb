{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","mount_file_id":"1DEzKAoIfFbVPlqWkimDszPoGVmN_pQX2","authorship_tag":"ABX9TyMvOnoqx/Hpyfr0vhYpnJm2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1. Data Preprocessing"],"metadata":{"id":"WB3JAA3P5kC3"}},{"cell_type":"markdown","source":["## 1.1 Combine Data from different sources\n","***Collected data from three different datasets including 9846+3512+2775 (16133 in total)dialogs.\n","Need to merge them into one single file for further processing.***\n"],"metadata":{"id":"2T39xpH-oAt5"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"HJnUnRwjSJ6A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_10K = pd.read_json('/content/drive/MyDrive/DataScience&Machinelearning/Projects/TherapyChatbot/data/Psychology-10K.json')\n","print(df_10K.shape)#(9846, 3), takes the last two columns only as Q and A"],"metadata":{"id":"MAfaF0apd7uZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_1 = df_10K.iloc[:,1:3]\n","df_1.columns = ['Question', 'Answer']\n"],"metadata":{"id":"FPJuekSLHQa9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#transform the unicode characters into plain string text\n","!pip install unidecode\n","from unidecode import unidecode"],"metadata":{"id":"AxsrpsdmgF8N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_combined = pd.read_json('/content/drive/MyDrive/DataScience&Machinelearning/Projects/TherapyChatbot/data/combined_dataset.json',encoding='utf-8')\n","print(df_combined.shape)#(3512, 2)\n","df_2 = df_combined\n","df_2.columns = ['Question', 'Answer']\n","df_2['Question'].apply(unidecode)\n","df_2['Answer'].apply(unidecode)\n"],"metadata":{"id":"GIMB0MGEeteH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_counsel = pd.read_csv('/content/drive/MyDrive/DataScience&Machinelearning/Projects/TherapyChatbot/data/20220401_counsel_chat.csv')\n","print(df_counsel.shape)#(2775, 10), takes questionTitle+questionText as Q, takes answerText as A\n","df_counsel.fillna('', inplace=True)# to avoid NaN Merge in case questionTitle or questionText is NaN\n","df_counsel['Merge'] = df_counsel['questionTitle']+df_counsel['questionText']"],"metadata":{"id":"wJ6QYhCzp-AV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_3 = df_counsel[['Merge','answerText']]\n","df_3.columns = ['Question', 'Answer']\n","\n","df_3.shape"],"metadata":{"id":"P5l8x3PwHcGo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#saved all the 16133 chats into a csv file\n","df = pd.concat([df_1, df_2, df_3], axis=0, ignore_index=True)\n","# df['Client'] = df['input'] + df['Context'] + df['Merge']\n","# df['Therapist'] = df['output'] + df['Response'] + df['answerText']\n","# df = df.drop(['input', 'output', 'Context', 'Response', 'Merge', 'answerText'], axis = 1)\n","print(df.shape)\n","\n","# use encoding utf-8-sig to handle the byte order mark (BOM), the default encoding for csv file is utf-8\n","df.to_csv('16133_chat.csv', index=False, encoding='utf-8-sig')\n","df.to_json('16133_chat.json')"],"metadata":{"id":"DCBn1oZ7rPE1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.2 Clean the data\n","***Clean the data from the following aspects***\n","\n","*   Remove rows with null values\n","*   Remove duplicate rows\n","*   Remove Non-English texts\n","*   Remove dialogs with too short answers\n","*   Unnecessary characters such as -------\n","*   Missing .\n","\n","\n","\n","\n"],"metadata":{"id":"NGlwWpoQzB0v"}},{"cell_type":"code","source":["import re\n","\n","df = pd.read_csv('16133_chat.csv')\n","print(df.shape)\n","# Remove rows with null values\n","df = df.dropna()\n","print(f'Shape of df after removing rows with null values {df.shape}')\n","\n","# Remove duplicate rows\n","df = df.drop_duplicates()\n","print(f'Shape of df after removing duplicate rows {df.shape}')\n","\n","# Remove dialogs with too short answers\n","min_text_length = 100\n","rows_too_short = df[df['Answer'].str.len() <= min_text_length]\n","print(rows_too_short)\n","df = df[df['Answer'].str.len() >= min_text_length]\n","print(f'Shape of df after removing too short answers {df.shape}')\n","\n","df['Answer'] = df['Answer'].apply(lambda x: re.sub(r'-+', '', x))\n"],"metadata":{"id":"APGKvGAirPgK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langdetect\n","!pip install nltk\n","import nltk\n","nltk.download('punkt')\n"],"metadata":{"id":"iO7o_BxMrPkE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langdetect import detect\n","from langdetect import detect_langs\n","from nltk.tokenize import sent_tokenize\n","import re\n","\n","# Function to detect the language of a text\n","def detect_language(text):\n","    try:\n","        return detect(text)\n","    except:\n","        return None\n","\n","def delete_non_en(text):\n","  # Detect the language for each word\n","  sentences = sent_tokenize(text)\n","  langs = [detect_language(sentence) for sentence in sentences]\n","  english_sentences = [sent for sent, lang in zip(sentences, langs) if lang == 'en']\n","  englist_text = ' '.join(english_sentences)\n","  return englist_text\n","\n","# Detect the language for each text in the specified column\n","df['language'] = df['Answer'].apply(detect_language)\n","# Remove non-English texts\n","df.loc[df['language'] != 'en', 'Answer'] = df.loc[df['language'] != 'en', 'Answer'].apply(lambda x: delete_non_en(x))\n","# rows_non_english = df[df['language'] != 'en']\n","# print(rows_non_english)\n","# Drop the 'language' column if desired\n","df.drop('language', axis=1, inplace=True)\n","\n"],"metadata":{"id":"p_kcUgM2IxL2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","# Example text with missing periods\n","text = \"This is a sentence without a period This is another sentence without a period\"\n","\n","# Regular expression pattern to detect missing periods\n","pattern = r'(?<=\\w)(?!\\s)(?!\\.)(?!\\?)'\n","\n","# Find all occurrences of the pattern\n","missing_periods = re.finditer(pattern, text)\n","\n","# Print the positions of the missing periods\n","for match in missing_periods:\n","    print(f\"Missing period at position: {match.start()}\")\n","\n","# Alternatively, you can replace the missing periods with a period\n","fixed_text = re.sub(pattern, '.', text)\n","print(fixed_text)"],"metadata":{"id":"uUyAABkOrkV_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.3 - Train, Validation and Test Split"],"metadata":{"id":"8FQEQmW13otg"}},{"cell_type":"code","source":["train_size = int (0.7 * len(df))\n","validation_size = int(0.2 * len(df))\n","shuffled_df = df.sample(frac=1, random_state=42)\n","train_df = shuffled_df[:train_size]\n","validation_df = shuffled_df[train_size:(train_size + validation_size)]\n","test_df = shuffled_df[train_size + validation_size:]\n","train_df.to_csv('train.csv', index=False)\n","validation_df.to_csv('validation.csv', index=False)\n","test_df.to_csv('test.csv', index=False)\n","\n","train_df.shape\n","test_df.shape"],"metadata":{"id":"fzypbY0W3miQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_df.shape)\n","print(test_df.shape)\n","print(validation_df.shape)"],"metadata":{"id":"zYraJQA65JY7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2 - Fine-tune the model"],"metadata":{"id":"_Td7AyQw50jN"}},{"cell_type":"markdown","source":["# 2.1 -Installation"],"metadata":{"id":"-9oQ09-r7ODt"}},{"cell_type":"code","source":["![ -d transformers ] || git clone --depth=1 https://github.com/huggingface/transformers"],"metadata":{"id":"neS-COQBqI1b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install --upgrade pip\n","!pip install --disable-pip-version-check \\\n","    torch==1.13.1 --quiet\n","    # torchdata==0.5.1 --quiet\n","\n","!pip install \\\n","    transformers==4.27.2 \\\n","    datasets==2.11.0 \\\n","    evaluate==0.4.0 \\\n","    rouge_score==0.1.2 \\\n","    loralib==0.1.1 \\\n","    peft==0.3.0 \\\n","    trl==0.4.4\n"],"metadata":{"id":"g50v-G7CrPlS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install --upgrade transformers"],"metadata":{"id":"18J2pGy5zqkV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n","from transformers import AutoModelForCausalLM, LlamaTokenizer, LlamaForCausalLM\n","import torch\n","import time\n","import evaluate\n","import pandas as pd\n","import numpy as np"],"metadata":{"id":"2puM99Ir6wel"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2 - Load Dataset and LLM"],"metadata":{"id":"W54G7duR7UTU"}},{"cell_type":"code","source":["dataset = load_dataset('csv', data_files={'train': 'train.csv', 'validation':'validation.csv', 'test': 'test.csv'})\n","dataset"],"metadata":{"id":"sT804NOr7XMl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_name='google/flan-t5-xxl'\n","original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","# model_name = 'NousResearch/Llama-2-7b-chat-hf'\n","# model_path = '/content/drive/MyDrive/llama-2-7b'\n","# original_model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n","# tokenizer = AutoTokenizer.from_pretrained(model_name)\n"],"metadata":{"id":"XIeO78tP8LAd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_number_of_trainable_model_parameters(model):\n","    trainable_model_parameters = 0\n","    all_model_parameters = 0\n","    for _, param in model.named_parameters():\n","      all_model_parameters += param.numel()\n","      if param.requires_grad:\n","        trainable_model_parameters += param.numel()\n","    return f\"trainable model parameters: {trainable_model_parameters}\\nall model parameters:{all_model_parameters}\\npercentage of trainable mdoel parameters: {trainable_model_parameters/all_model_parameters}\"\n","\n","print(print_number_of_trainable_model_parameters(original_model))"],"metadata":{"id":"fLPGUYXO8sJN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.3 - Test the model with zero shot inferencing"],"metadata":{"id":"XwfRHN3J-KTZ"}},{"cell_type":"code","source":["index = 205\n","\n","question = dataset['test'][index]['Question']\n","answer = dataset['test'][index]['Answer']\n","\n","prompt = f\"\"\"\n","If you are a licensed psychologist, please provide this patient with a helpful response to their concern.\n","\n","{question}\n","\n","Reply:\n","\"\"\"\n","\n","inputs = tokenizer(prompt, return_tensors='pt')\n","output = tokenizer.decode(original_model.generate(inputs['input_ids'], max_new_tokens=200,)[0], skip_special_tokens=True)\n","\n","dash_line = '_'.join('' for x in range(100))\n","print(dash_line)\n","print(f\"INPUT PROMPT:\\n{prompt}\")\n","print(dash_line)\n","print(f'REAL THERAPIST REPLY:\\n{answer}\\n')\n","print(dash_line)\n","print(f'MODEL GENERATION REPLY - ZERO SHOT:\\n {output}')"],"metadata":{"id":"4YkZQfEA-O6b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3 - Perform full fine_tuning\n","\n"],"metadata":{"id":"iWuN73h2DK5_"}},{"cell_type":"markdown","source":["## 3.1 - Preprocess the Question-Answer Dataset"],"metadata":{"id":"XFKDS2LpDY-i"}},{"cell_type":"code","source":["from torch.utils.data import random_split\n","\n","def tokenize_function(example):\n","    start_prompt = 'If you are a licensed psychologist, please provide this patient with a helpful response to their concern.\\n\\n'\n","    end_prompt = '\\n\\nReply:'\n","    prompt = [start_prompt + dialogue + end_prompt for dialogue in example['Question']]\n","    # print(tokenizer(prompt, padding='max_length', truncation=True, return_tensors='pt').input_ids.shape)\n","    example['input_ids'] = pd.Series(tokenizer(prompt, padding='max_length', truncation=True, return_tensors='pt')[\"input_ids\"].numpy().tolist())\n","    example['labels'] = tokenizer(example['Answer'], padding='max_length', truncation=True, return_tensors='pt')[\"input_ids\"]\n","\n","    return example\n","\n","tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","tokenized_dataset = tokenized_dataset.remove_columns(['Question', 'Answer'])\n","#subsample the dataset\n","# tokenized_dataset = tokenized_dataset.filter(lambda row, index: index % 10 == 0, with_indices = True)\n","\n"],"metadata":{"id":"k_ufN565DWi5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.2 - Fine-Tune the model with the tokenized dataset"],"metadata":{"id":"bWy8YhjKJJ5G"}},{"cell_type":"code","source":["fine_tune_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n"],"metadata":{"id":"VcI81RoKJJNX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_dir = f'./drive/MyDrive/aitherapy/therapist-ai-training-{str(int(time.time()))}'\n","\n","training_args = TrainingArguments(\n","    output_dir=output_dir,\n","    learning_rate=1e-4,\n","    num_train_epochs=10,\n","    weight_decay=0.02,\n","    logging_steps=100,\n","    max_steps=2000\n",")\n","\n","trainer = Trainer(\n","    model=fine_tune_model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset['train'],\n","    eval_dataset=tokenized_dataset['validation']\n",")"],"metadata":{"id":"mnJAtuV0VJXA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"ZenLvtdLLNKB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.3 - Evaluate the model qualitatively"],"metadata":{"id":"TqZ5LLe7LmvO"}},{"cell_type":"code","source":["index = 205\n","\n","question = dataset['test'][index]['Question']\n","answer = dataset['test'][index]['Answer']\n","\n","prompt = f\"\"\"\n","If you are a licensed psychologist, please provide this patient with a helpful response to their concern.\n","{question}\n","\n","Reply:\n","\"\"\"\n","\n","inputs = tokenizer(prompt, return_tensors='pt').input_ids.to('cuda')\n","model_output = fine_tune_model.generate(inputs, max_new_tokens=200, num_beams=1)\n","model_text_output = tokenizer.decode(model_output[0], skip_special_tokens=True)\n","\n","\n","dash_line = '_'.join('' for x in range(100))\n","print(dash_line)\n","print(f\"INPUT PROMPT:\\n{prompt}\")\n","print(dash_line)\n","print(f'REAL THERAPIST REPLY:\\n{answer}\\n')\n","print(dash_line)\n","print(f'MODEL GENERATION REPLY - Fine Tuned:\\n {model_text_output}')"],"metadata":{"id":"l77EMzK5Lq5r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.4 - Evaluate the model quantitatively (with ROUGE metric)"],"metadata":{"id":"shCsiPwVM78p"}},{"cell_type":"code","source":["rouge = evaluate.load('rouge')"],"metadata":{"id":"eHqsBianM7K9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["questions = dataset['test'][0:10]['Question']\n","real_therapy_replies = dataset['test'][0:10]['Answer']\n","\n","model_replies = []\n","\n","for _, question in enumerate(questions):\n","  prompt = f\"\"\"\n","If you are a licensed psychologist, please provide this patient with a helpful response to their concern.\n","  {question}\n","  Reply:\"\"\"\n","  input_ids = tokenizer(prompt, return_tensors='pt').input_ids.to('cuda')\n","\n","  model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n","  model_text_outputs = tokenizer.decode(model_outputs[0], skip_special_tokens=True)\n","  model_replies.append(model_text_outputs)\n","\n","zipped_summaries = list(zip(real_therapy_replies, model_replies))\n","\n","df = pd.DataFrame(zipped_summaries, columns = ['real_therapy_replies', 'model_replies'])\n","\n","model_results = rouge.compute(\n","    predictions=model_replies,\n","    references=real_therapy_replies[0:len(model_replies)],\n","    use_aggregator=True,\n","    use_stemmer=True,\n",")\n","\n","print('model rouge:')\n","print(model_results)"],"metadata":{"id":"1DwvTw5QN1hg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4 - Perform Parameter Efficient Fine-Tuning (PEFT)"],"metadata":{"id":"itRAF_BiWqH-"}},{"cell_type":"markdown","source":["## 4.1 - Setup the PEFT/LoRA model for fine-tuning"],"metadata":{"id":"cScsIv3OWw1G"}},{"cell_type":"code","source":["from peft import LoraConfig, get_peft_model, TaskType\n","\n","lora_config = LoraConfig(\n","    r=32,\n","    lora_alpha=32,\n","    target_modules=['q','v'],\n","    lora_dropout=0.05,\n","    bias='none',\n","    task_type=TaskType.SEQ_2_SEQ_LM\n",")"],"metadata":{"id":"fU9pEo67Lr9U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["original_peft_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n","peft_model = get_peft_model(original_peft_model, lora_config)\n","print(print_number_of_trainable_model_parameters(peft_model))"],"metadata":{"id":"zW1zEHU0XTHs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.2 - Train PEFT Adapter"],"metadata":{"id":"YJJgUW9TXhp3"}},{"cell_type":"code","source":["output_dir = f'./peft-ai-therapist-training-{str(int(time.time()))}'\n","\n","peft_training_args = TrainingArguments(\n","    output_dir=output_dir,\n","    auto_find_batch_size=True,\n","    learning_rate=1e-3,\n","    num_train_epochs=5,\n","    logging_steps=100,\n","    max_steps=2000\n",")\n","\n","peft_trainer = Trainer(\n","    model=peft_model,\n","    args=peft_training_args,\n","    train_dataset=tokenized_dataset['train'],\n",")"],"metadata":{"id":"PL4uG-ylXkpx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["peft_trainer.train()\n","\n","peft_model_path = './peft_ai_therapist_checkpoint_local'\n","\n","peft_trainer.model.save_pretrained(peft_model_path)\n","tokenizer.save_pretrained(peft_model_path)"],"metadata":{"id":"AiqL1sGSYOBK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from peft import PeftModel, PeftConfig\n","\n","peft_model_base = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base', torch_dtype=torch.bfloat16)\n","tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')\n","\n","peft_model = PeftModel.from_pretrained(peft_model_base,\n","                                       './peft_ai_therapist_checkpoint_local/',\n","                                       torch_dtype=torch.bfloat16,\n","                                       is_trainable=False).to('cuda')\n","print(print_number_of_trainable_model_parameters(peft_model))"],"metadata":{"id":"j6ZAsczeY_cU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.3 - Evaluate the model qualitatively"],"metadata":{"id":"fhr70mPFZujy"}},{"cell_type":"code","source":["index = 100\n","\n","question = dataset['test'][index]['Question']\n","answer = dataset['test'][index]['Answer']\n","\n","prompt = f\"\"\"\n","If you are a licensed psychologist, please provide this patient with a helpful response to their concern.\n","\n","{question}\n","\n","Reply:\n","\"\"\"\n","\n","inputs = tokenizer(prompt, return_tensors='pt').input_ids.to('cuda')\n","\n","original_model_outputs = original_model.generate(inputs, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n","original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n","\n","peft_model_outputs = peft_model.generate(inputs=inputs, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n","peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n","\n","dash_line = '_'.join('' for x in range(100))\n","print(dash_line)\n","print(f\"INPUT PROMPT:\\n{prompt}\")\n","print(dash_line)\n","print(f'REAL THERAPIST REPLY:\\n{answer}\\n')\n","print(dash_line)\n","print(f'Original MODEL GENERATION REPLY - Fine Tuned:\\n {original_model_text_output}')\n","print(dash_line)\n","print(f'PEFT MODEL GENERATION REPLY - Fine Tuned:\\n {peft_model_text_output}')"],"metadata":{"id":"h8ap7hFhZ4Yz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.4 - Evaluate the model quantitatively (ROUGE)"],"metadata":{"id":"7fqTUmPdaeiK"}},{"cell_type":"code","source":["questions = dataset['test'][0:10]['Question']\n","real_therapy_replies = dataset['test'][0:10]['Answer']\n","\n","original_model_replies = []\n","peft_model_replies = []\n","\n","for _, question in enumerate(questions):\n","  prompt = f\"\"\"\n","If you are a licensed psychologist, please provide this patient with a helpful response to their concern.\n","  {question}\n","  Reply:\"\"\"\n","  input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n","\n","  original_model_outputs = original_model.generate(input_ids=inputs, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n","  original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n","\n","  peft_model_outputs = peft_model.generate(input_ids=inputs, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n","  peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n","\n","  original_model_replies.append(original_model_text_output)\n","  peft_model_replies.append(peft_model_text_output)\n","\n","zipped_summaries = list(zip(real_therapy_replies, original_model_replies, peft_model_replies))\n","\n","df = pd.DataFrame(zipped_summaries, columns = ['real_therapy_replies', 'original_model_replies', 'peft_model_replies'])\n","\n","original_model_results = rouge.compute(\n","    predictions=original_model_replies,\n","    references=real_therapy_replies[0:len(original_model_replies)],\n","    use_aggregator=True,\n","    use_stemmer=True,\n",")\n","\n","peft_model_results = rouge.compute(\n","    predictions=peft_model_replies,\n","    references=real_therapy_replies[0:len(peft_model_replies)],\n","    use_aggregator=True,\n","    use_stemmer=True,\n",")\n","print('original model rouge:')\n","print(original_model_results)\n","print('peft model rouge:')\n","print(peft_model_results)\n"],"metadata":{"id":"5RmN_pSzajmd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5 - Fine-Tune FLAN-T5 with reinforcement Learning (PPO) and PEFT to Generate More-Empathetic Relies"],"metadata":{"id":"8ZjD_uv1Vnh_"}},{"cell_type":"markdown","source":["## 5.1 - Set up Kernel and Required Dependencies"],"metadata":{"id":"Co2lxQxPWyjG"}},{"cell_type":"code","source":["from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, GenerationConfig\n","from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n","\n","#trl: transformer reinforcement learning library\n","from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n","from trl import create_reference_model\n","from trl.core import LengthSampler\n","\n","# tqdm library makes the loops show a smart progress meter\n","from tqdm import tqdm\n","tqdm.pandas()"],"metadata":{"id":"3gyZqVIeWs9i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5.2 - Prepare Reward Model and Empathy Evaluator"],"metadata":{"id":"x9lHn1xCc_FG"}},{"cell_type":"markdown","source":["### 5.2.1 - Load Data and PPO model"],"metadata":{"id":"_OJgxGwEdHnZ"}},{"cell_type":"code","source":["def tokenize(example):\n","  prompt = f\"\"\"\n","If you are a licensed psychologist, please provide this patient with a helpful response to their concern.\n","\n","{question}\n","\n","Reply:\n","\"\"\"\n","  example['input_ids'] = tokenizer.encode(prompt)\n","  example['query'] = tokenizer.decode(example['input_ids'])\n","  return example\n","\n","# dataset = load_dataset('csv', data_files={'train': 'train.csv', 'validation':'validation.csv', 'test': 'test.csv'})\n","ppo_dataset = dataset.map(tokenize, batched=False)\n","ppo_dataset.set_format(type='torch')\n"],"metadata":{"id":"FXUPdQ_0dG29"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model, torch_type=torch.bfloat16, is_trainable=True)\n","print(f'PPO model parameters to be update:\\n {print_number_of_trainable_model_parameters(ppo_model)}\\n')#valuehead + 769\n","print(ppo_model.v_head)"],"metadata":{"id":"bGXK4aQ9M2Wi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ref_model = create_reference_model(ppo_model)\n","print(f'reference model parameters to be updated:\\n{print_number_of_trainable_model_parameters(ref_model)}\\n')\n"],"metadata":{"id":"hq8XB0rcN19y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5.2.2 - Prepare Reward Model"],"metadata":{"id":"py_gInB_aqtb"}},{"cell_type":"code","source":["empathy_model_name = 'facebook/roberta-hate-speech-dynabench-r4-target'\n","empathy_tokenizer = AutoTokenizer.from_pretrained(empathy_model_name, device_map='auto')\n","empathy_model = AutoModelForSequenceClassification.from_pretrained(empathy_model_name, device_map='auto')\n","print(empathy_model.config.id2label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"id":"Us4QXTgVaxL8","executionInfo":{"status":"error","timestamp":1691694566858,"user_tz":-120,"elapsed":4,"user":{"displayName":"Hong Lu","userId":"18117207304411534237"}},"outputId":"6de6accf-a78b-4baf-8a4c-75c6458938c1"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6b904f6bef8e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mempathy_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'facebook/roberta-hate-speech-dynabench-r4-target'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mempathy_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempathy_model_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mempathy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempathy_model_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempathy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"]}]},{"cell_type":"code","source":["empathy_text = 'That is not your fault at all'\n","\n","empathy_input_ids = empathy_tokenizer(empathy_text, return_tensors='pt').input_ids.to('cuda')\n","\n","logits = empathy_model(input_ids=empathy_input_ids).logits\n","print(f'ligits [empathic, not empathic]:{logits.tolist()[0]}')\n","\n","probabilities = logits.softmax(dim=-1).tolist()[0]\n","print(f'probabilities [empathic, not empathic]: {probabilities}')\n","\n","empathy_index = 0\n","empathy_reward = (logits[:,empathy_index]).tolist()\n","print(f'reward (low): {empathy_reward}')"],"metadata":{"id":"MjcH-UjJbeyi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["non_empathy_text = 'That is all your fault'\n","\n","empathy_input_ids = empathy_tokenizer(non_empathy_text, return_tensors='pt').input_ids.to('cuda')\n","\n","logits = empathy_model(input_ids=empathy_input_ids).logits\n","print(f'ligits [empathic, not empathic]:{logits.tolist()[0]}')\n","\n","probabilities = logits.softmax(dim=-1).tolist()[0]\n","print(f'probabilities [empathic, not empathic]: {probabilities}')\n","\n","empathy_index = 0\n","empathy_reward = (logits[:,empathy_index]).tolist()\n","print(f'reward (high): {empathy_reward}')"],"metadata":{"id":"Q5FwS0USdHJM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 0 if torch.cuda.is_available() else 'cpu'\n","\n","sentiment_pipe = pipeline('sentiment-analysis',\n","                          model=empathy_model_name,\n","                          device=device)\n","reward_logits_kwargs = {\n","    'top_k': None,\n","    'function_to_apply':'none',\n","    'batch_size':16\n","}\n","\n","reward_probabilities_kwargs={\n","    'top_k': None,\n","    'function_to_apply':'softmax',\n","    'batch_size':16\n","}\n","\n","print('Reward model output for empathic text:')\n","print(sentiment_pipe(empathy_text, **reward_logits_kwargs))\n","print(sentiment_pipe(empathy_text, **reward_probabilities_kwargs))\n","print('Reward model output for non-empathic text:')\n","print(sentiment_pipe(non_empathy_text, **reward_logits_kwargs))\n","print(sentiment_pipe(non_empathy_text, **reward_probabilities_kwargs))"],"metadata":{"id":"dkud-4oGdhk9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5.2.3 - Evaluate Empathy"],"metadata":{"id":"_pBzjGY1hPSx"}},{"cell_type":"code","source":["empathy_evaluator = evaluate.load('toxicity',\n","                                  empathy_model_name,\n","                                  module_type='measurement',\n","                                  toxic_label='hate')"],"metadata":{"id":"fk1zpRQMhSeD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["empathy_score = empathy_evaluator.compute(predictions=[non_empathy_text])\n","print('Empathy score for non-empathy text: ')\n","print(empathy_score['toxicity'])\n","\n","empathy_score = empathy_evaluator.compute(predictions=[empathy_text])\n","print('Empathy score for empathy text:')\n","print(empathy_score['toxicity'])"],"metadata":{"id":"epVRl3nOhmBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_empathy(model,\n","                     empathy_evaluator,\n","                     tokenizer,\n","                     dataset,\n","                     num_samples):\n","  max_new_tokens = 200\n","  empathies = []\n","  input_texts = []\n","  for i, sample in tqdm(enumerate(dataset)):\n","    input_text = sample['query']\n","\n","    if i > num_samples:\n","      break\n","\n","    input_ids = tokenizer(input_text, return_tensors='pt', padding=True).input_ids.to('cuda')\n","\n","    generation_config = GenerationConfig(max_new_tokens=max_new_tokens,\n","                                         tok_k=0.0,\n","                                         top_p=1.0,\n","                                         do_sample=True)\n","\n","    response_token_ids = model.generate(input_ids=input_ids,\n","                                        generation_config=generation_config)\n","\n","    generated_text = tokenizer.decode(response_token_ids[0], skip_special_tokens=True)\n","\n","    empathy_score = empathy_evaluator.compute(predictions=[input_text + ' ' + generated_text])\n","\n","    empathies.extend(empathy_score['toxicity'])\n","\n","  mean = np.mean(empathies)\n","  std = np.std(empathies)\n","\n","  return mean, std"],"metadata":{"id":"AUuHbMPniCL0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(model_name, device_map='cuda')\n","mean_before_detoxification, std_before_detoxification = evaluate_empathy(model=ref_model,\n","                                                                         empathy_evaluator=empathy_evaluator,\n","                                                                         tokenizer=tokenizer,\n","                                                                         dataset=ppo_dataset['test'],\n","                                                                         num_samples=10)\n","\n","print(f'empathy [mean, std] before detox: [{mean_before_detoxification, std_before_detoxification}]')"],"metadata":{"id":"Dm-Nl0NtlqGB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5.3 - Perform Fine-Tuning to Empathize the Replies"],"metadata":{"id":"9_gHRkdzmaA7"}},{"cell_type":"markdown","source":["### 5.3.1 - Initialize PPOTrainer"],"metadata":{"id":"sZkJdPCFmmqw"}},{"cell_type":"code","source":["learning_rate = 1.41e-5\n","max_ppo_epochs = 10\n","mini_batch_size = 4\n","batch_size = 16\n","\n","config = PPOConfig(\n","    model_name=model_name,\n","    learning_rate=learning_rate,\n","    ppo_epochs=max_ppo_epochs,\n","    mini_batch_size=mini_batch_size,\n","    batch_size=batch_size\n",")\n","\n","def collator(data):\n","  return dict((key, [d[key] for d in data]) for key in data[0])\n","\n","ppo_trainer = PPOTrainer(config=config,\n","                         model=ppo_model,\n","                         tokenizer=tokenizer,\n","                         dataset=ppo_dataset['train'],\n","                         data_collator=collator)"],"metadata":{"id":"UYI668Qkmk_R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5.3.2 - Fine-tune the model"],"metadata":{"id":"51XCSGmTnabZ"}},{"cell_type":"code","source":["output_min_length = 100\n","output_max_length = 400\n","output_length_sampler = LengthSampler(output_min_length, output_max_length)\n","\n","generation_kwargs = {\n","    'min_length': 5,\n","    'top_k': 0.0,\n","    \"top_p\": 1.0,\n","    'do_sample': True\n","}\n","\n","reward_kwargs = {\n","    'top_k': None,\n","    'function_to_apply': 'none',\n","    'batch_size': 16\n","}\n","\n","max_ppo_steps = 10\n","\n","for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n","  if step > max_ppo_steps:\n","    break\n","\n","  prompt_tensors = batch['input_ids']\n","  reply_tensors = []\n","\n","  for prompt_tensor in prompt_tensors:\n","    max_new_tokens = output_length_sampler()\n","\n","    generation_kwargs['max_new_tokens'] = max_new_tokens\n","    reply = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n","\n","    reply_tensors.append(reply.squeeze()[-max_new_tokens:])\n","\n","  batch['response'] = [tokenizer.decode(r.squeeze()) for r in reply_tensors]\n","\n","  query_response_pairs = [q + r for q, r in zip(batch['query'], batch['response'])]\n","  rewards = sentiment_pipe(query_response_pairs, **reward_kwargs)\n","\n","  reward_tensors = [torch.tensor(reward[empathy_index]['score']) for reward in rewards]\n","\n","  stats = ppo_trainer.step(prompt_tensors, reply_tensors, reward_tensors)\n","  ppo_trainer.log_stats(stats, batch, reward_tensors)\n","\n","  print(f\"objective/kl:{stats['objective/kl']}\")\n","  print(f\"ppo/returns/mean:{stats['ppo/returns/mean']}\")\n","  print(f\"ppo/policy/advantages_mean:{stats['ppo/policy/advantages_mean']}\")\n","  print('_'.join('' for x in range(100)))"],"metadata":{"id":"eRx9QjtpndB1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5.3.3 - Evaluate the model qualitatively"],"metadata":{"id":"XN-Xt8qoWKP2"}},{"cell_type":"code","source":["batch_size = 20\n","compare_results = {}\n","\n","df_batch = ppo_dataset['test'][0:batch_size]\n","\n","compare_results['query'] = df_batch['query']\n","prompt_tensors = df_batch['input_ids']\n","\n","reply_tensors_ref = []\n","reply_tensors = []\n","\n","for i in tqdm(range(batch_size)):\n","  gen_len = output_length_sampler()\n","  generation_kwargs['max_new_tokens'] = gen_len\n","\n","  reply = ref_model.generate(input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n","                                                       **generation_kwargs).squeeze()[-gen_len:]\n","  reply_tensors_ref.append(reply)\n","  reply = ppo_model.generate(input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n","                                                       **generation_kwargs).squeeze()[-gen_len:]\n","  reply_tensors.append(reply)\n","\n","compare_results['response_before'] = [tokenizer.decode(reply_tensors_ref[i]) for i in range(batch_size)]\n","compare_results['response_after'] = [tokenizer.decode(reply_tensors[i]) for i in range(batch_size)]\n","\n","texts_before = [d + s for d, s in zip(compare_results['query'], compare_results['response_before'])]\n","rewards_before = sentiment_pipe(texts_before, **reward_kwargs)\n","compare_results['reward_before'] = [reward[empathy_index]['score'] for reward in rewards_before]\n","\n","texts_after = [d + s for d, s in zip(compare_results['query'], compare_results['response_after'])]\n","rewards_after = sentiment_pipe(texts_after, **reward_kwargs)\n","compare_results['reward_after'] = [reward[empathy_index]['score'] for reward in rewards_after]"],"metadata":{"id":"jt-gfIMqWJlE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.set_option('display.max_colwidth', 500)\n","df_compare_results = pd.DataFrame(compare_results)\n","df_compare_results['reward_diff'] = df_compare_results['reward_after'] - df_compare_results['reward_before']\n","df_compare_results_sorted = df_compare_results.sort_values(by=['reward_diff'], ascending=False).reset_index(drop=True)"],"metadata":{"id":"C8Iwm5fSYuSr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_compare_results_sorted"],"metadata":{"id":"3X4JI2PO7ejL"},"execution_count":null,"outputs":[]}]}